{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoUakzK8yt1A+BzQhu7EKg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaaat/Machine_learning-Deep_learning/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBFo4TYzVn2O",
        "outputId": "55410168-cf78-4f83-bd44-966984ee42bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml(name = \"Mnist_784\", version = 1)\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "image_index = X.iloc[0].to_numpy()\n",
        "image = image_index.reshape(28, 28)\n",
        "plt.imshow(image, cmap = mpl.cm.binary, interpolation = \"nearest\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "2emsQf-HWjlV",
        "outputId": "3f649cd4-6cca-4e81-f861-75a992092782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykRzork7XyKr",
        "outputId": "68747510-4e63-496b-fe71-51ab4d2cb55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#Change y into int-preferable default\n",
        "y = y.astype(np.uint8)\n",
        "#Fetch training and testing set\n",
        "X_train, y_train, X_test, y_test = X[:60000], y[:60000], X[60000:], y[60000:]\n",
        "print(f\"X_train: {len(X_train)}\")\n",
        "print(f\"y_train: {len(y_train)}\")\n",
        "print(f\"X_test: {len(X_test)}\")\n",
        "print(f\"y_test: {len(y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZRm40qOYBCy",
        "outputId": "316fff7f-416c-4236-c58d-f75b20b8dec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: 60000\n",
            "y_train: 60000\n",
            "X_test: 10000\n",
            "y_test: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let us pick and Train a Binary Classier"
      ],
      "metadata": {
        "id": "biTK5uwjZZ_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We will make it simple, and only identify one digit for now, X[0]\n",
        "#We define our y_train and y_test targets\n",
        "y_train_target = (y_train ==5) #We are targetting to classify whether it is a 5 or not\n",
        "y_test_target = (y_test == 5)\n"
      ],
      "metadata": {
        "id": "TRAGM5OvZS5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We pick a model\n",
        "#SGD classifier is preprered\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "model_1 = SGDClassifier(random_state = 42)\n",
        "model_1.fit(X_train, y_train_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "kkvO0psFZc9G",
        "outputId": "aa10384a-85d6-4817-f8f5-8a92b618b6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let us make some predictions\n",
        "model_1.predict([image_index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPz0zyQebVL9",
        "outputId": "3fbbf3b6-dc80-4a47-d995-ceac316a8984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Performance Measures\n"
      ],
      "metadata": {
        "id": "J7if-mVxcm15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Measuring Accuracy Using Cross-Validation\n",
        "    #Let us impliment cross validation by ourselves, and not rely on what sklearn provides for us\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.base import clone\n",
        "#We define skfolds\n",
        "\n",
        "skfolds = StratifiedKFold(n_splits = 3, shuffle = True, random_state = 42)\n",
        "#Let us get X_trainfolds, and y train, test folds\n",
        "for train_index, test_index in skfolds.split(X_train, y_train_target):\n",
        "#We get a cloned model\n",
        "  cloned_model_1 = clone(model_1)\n",
        "#Then, let us fetch train skfolds, and test skfolds\n",
        "  X_train_folds  = X_train.iloc[train_index]\n",
        "  y_train_target_folds = y_train_target.iloc[train_index]\n",
        "  X_test_folds = X_train.iloc[test_index]\n",
        "  y_test_target_folds = y_train_target.iloc[test_index]\n",
        "\n",
        "  #We then make preds with our cloned model using the Kfolds\n",
        "  cloned_model_1.fit(X_train_folds, y_train_target_folds)\n",
        "  test_preds = cloned_model_1.predict(X_test_folds)\n",
        "  #We proceed to accuracy calculation\n",
        "  n_correct = sum(test_preds == y_test_target_folds)\n",
        "  print(n_correct/len(test_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9mAHkhzcZgC",
        "outputId": "0d1fe3be-e14f-430d-a404-fd68a312bbfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9669\n",
            "0.91625\n",
            "0.96785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Nice. Let’s use the cross_val_score() function to evaluate your SGDClassifier model\n",
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(model_1, X_train, y_train_target, scoring = \"accuracy\", cv = 3)\n",
        "scores = (scores*100)\n",
        "print(scores)\n",
        "#Nice Nice Nicee!!!! As we can see from the output, the model accuracy is awesome (96.035%)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLT_KiCScoMA",
        "outputId": "bc078cbe-3bc3-452f-bb23-91668ef71e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[95.035 96.035 96.04 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us look at another classifer, more probably, a very dumb one\n",
        "from sklearn.base import BaseEstimator\n",
        "class NewClassifier(BaseEstimator):\n",
        "  def fit(self, X, y=None):\n",
        "    pass\n",
        "  def predict(self, X):\n",
        "    return np.zeros((len(X), 1), dtype=bool)\n",
        "\n",
        "\n",
        "#Nice. Let us fetch our mode\n",
        "model_2 = NewClassifier()\n",
        "#Let us go and evaluate its accuracy straight away\n",
        "model_2_scores = cross_val_score(model_2, X_train, y_train_target, scoring = \"accuracy\", cv = 3)\n",
        "print(model_2_scores)\n",
        "#it has over 90% accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FjVk2CAjo3j",
        "outputId": "de4ed4ee-131d-4a7e-c362-5d99a36b0579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.91125 0.90855 0.90915]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix"
      ],
      "metadata": {
        "id": "De7Uu1dNzKmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We first need to have test predictions. We can do this, however by not touching on our test set\n",
        "#Let us use the cross_val_predict\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "train_preds = cross_val_predict(model_1, X_train, y_train_target, cv = 3)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix_scores = confusion_matrix(y_train_target, train_preds)\n",
        "print(confusion_matrix_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n53PI1JEyeXx",
        "outputId": "aebda106-efbb-4d2e-abb2-79bd4a8c116a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[53892   687]\n",
            " [ 1891  3530]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To say, [53892 are not 5, and yes, they are classified as not 5 (True negatives)\n",
        "# 687 are not 5, yet they are classified as 5. (False positives)\n",
        "# 1891, they are 5s, yet the model wrongly classified them as not being 5s(false negatives).\n",
        "# 3530 are indeed 5s, and the model classified them as 5s (True positives)"
      ],
      "metadata": {
        "id": "zz_4CBbZzMbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpreting the consufion matrix"
      ],
      "metadata": {
        "id": "PruYBad32sQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Each row in a confusion matrix represents an actual class, while each column repre‐\n",
        "sents a predicted class. The first row of this matrix considers non-5 images (the nega‐\n",
        "tive class): 53892 of them were correctly classified as non-5s (they are called true\n",
        "negatives), while the remaining 687 were wrongly classified as 5s (false positives).\n",
        "The second row considers the images of 5s (the positive class): 1,891 were wrongly\n",
        "classified as non-5s (false negatives), while the remaining 3530 were correctly classi‐\n",
        "fied as 5s (true positives).\n",
        "A perfect classifier would have only true positives and true\n",
        "negatives, so its confusion matrix would have nonzero values only on its main diago‐\n",
        "nal (top left to bottom right):\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1tsvyvA_2xTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us condider how a confusion matrix of a perfect preiction would be\n",
        "y_train_perfect_preds = y_train_target\n",
        "perfect__confusion_matrix_scores = confusion_matrix(y_train_target, y_train_perfect_preds)\n",
        "print(perfect__confusion_matrix_scores )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0R88wdj5ByX",
        "outputId": "f88a2816-8856-44cc-bca3-641bf35c3ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[54579     0]\n",
            " [    0  5421]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#precision\n"
      ],
      "metadata": {
        "id": "8njTzbOR6hOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" The confusion matrix gives a lot of information, but sometimes we may prefer a\n",
        "more concise metric.\n",
        "An interesting one to look at is the accuracy of the positive pre‐\n",
        "dictions; this is called the precision of the classifier (Equation 3-1).\n",
        "Equation 3-1. Precision\n",
        "precision = TP/(TP + FP)\"\"\""
      ],
      "metadata": {
        "id": "tzMSbG2n6iq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\" A trivial way to have perfect precision is to make one single positive prediction and\n",
        "ensure it is correct (precision = 1/1 = 100%). This would not be very useful since the\n",
        "classifier would ignore all but one positive instance. So precision is typically used\n",
        "along with another metric named recall, also called sensitivity or true positive rate (TPR): this is the ratio of positive instances that are correctly detected by the classifier\n",
        " \"\"\""
      ],
      "metadata": {
        "id": "hTtQ7PD97DQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Precision and Recall"
      ],
      "metadata": {
        "id": "FRf34tHZ7g6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "print(f\"prediction_score: {precision_score(y_train_target, train_preds)}\")\n",
        "print(f\"recall_score: {recall_score(y_train_target, train_preds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rYDZ5P56xy7",
        "outputId": "a9e5bfde-9a84-4b47-d614-f1708308d4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction_score: 0.8370879772350012\n",
            "recall_score: 0.6511713705958311\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"\" As above, When our model claims an image represents a 5, it is correct only 83.7% of the time. Moreover, it only detects 65.1% of the 5s\"\"\""
      ],
      "metadata": {
        "id": "jPBi2Ozg9Mc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"It is often convenient to combine precision and recall into a single metric called the F1\n",
        "score, in particular if we need a simple way to compare two classifiers. The F1\n",
        " score is the harmonic mean of precision and recall  \"\"\"\n",
        "from sklearn.metrics import f1_score\n",
        "f1_score = f1_score(y_train_target, train_preds)\n",
        "print(f\"f1_-score: {f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcHBJlqK9cws",
        "outputId": "906eb585-6426-48f1-8a28-6b3928150821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_-score: 0.7325171197343846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#COPIED\n",
        "\"\"\"The F1\n",
        "score favors classifiers that have similar precision and recall. This is not always\n",
        "what you want: in some contexts you mostly care about precision, and in other con‐\n",
        "texts you really care about recall. For example, if you trained a classifier to detect vid‐\n",
        "eos that are safe for kids, you would probably prefer a classifier that rejects many\n",
        "good videos (low recall) but keeps only safe ones (high precision), rather than a clas‐\n",
        "sifier that has a much higher recall but lets a few really bad videos show up in your\n",
        "product (in such cases, you may even want to add a human pipeline to check the clas‐\n",
        "sifier’s video selection). On the other hand, suppose you train a classifier to detect\n",
        "shoplifters on surveillance images: it is probably fine if your classifier has only 30%\n",
        "precision as long as it has 99% recall (sure, the security guards will get a few false\n",
        "alerts, but almost all shoplifters will get caught) \"\"\"\n",
        "\n",
        "\"\"\"Unfortunately, you can’t have it both ways: increasing precision reduces recall, and\n",
        "vice versa. This is called the precision/recall tradeo \"\"\""
      ],
      "metadata": {
        "id": "p8iaBJB1-3o5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jgFsjcDp-7zF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}